# 锁的实现
## Test And Set
```
// 逻辑上
// return what was pointed to by addr
// at the same time, store newval into addr atomically
int TAS(int *addr, int newval) {
    int old = *addr;
    *addr = newval;
    return old;
} 

// 实际上
int TAS(volatile int *addr, int newval) {
    int result = newval;
    asm volatile("lock; xchg %0, %1"
                 : "+m" (*addr), "=r" (result)
                 : "1" (newval)
                 : "cc");
    return result;
}
```

## FAA
```
// 逻辑上
int FAA(int *ptr) {
    int old = *ptr;
    *ptr = old + 1;
    return old;
}

// 实际上
// Let’s use GCC’s built-in
// atomic functions this time around
__sync_fetch_and_add(ptr, 1)
```

以下的这些实现都是以cache一致性最严格的情况下，需要自己控制memory order

## 基于TAS的实现
```
typedef struct __lock_t {
    int flag;
} lock_t;
void init(lock_t *lock) {
    lock->flag = 0;
}
void acquire(lock_t *lock) {
    while (TAS(&lock->flag, 1) == 1)
        ; // spin-wait (do nothing)
}
void release(lock_t *lock) {
    lock->flag = 0;
} 
```

评价一个锁要从5个方面来考察，分别是：
- 互斥执行：只有一个线程在临界区内。
- 无死锁：如果有多个同时请求锁，必须有一个能够进展下去
- 有限等待：必须允许每个等待的线程都能进入
- 公平性：以请求锁的顺序获得锁
- 性能：对CPU来说要运行高效

显然，使用TAS实现的锁不具备3、4、5特性，原因如下：
1. 有的线程可能会一直拿不到锁导致“饿死”
2. 并没有以请求锁的顺序分配锁，而是“抢”的
3. 在循环等待，对CPU利用不高效


## Ticket Lock
```
typedef struct {
    int ticket;
    int turn;
} lock_t;

void lock_init(lock_t *lock) {
    lock->ticket = 0;
    lock->turn = 0;
}

void acquire(lock_t *lock) {
    int myturn = FAA(&lock->ticket);
    while (lock->turn != myturn)
        ; // spin
}

void release(lock_t *lock) {
    lock->turn += 1;
}

```

这样的话就解决了有限等待和公平性的问题：每个请求先去排队“拿号”，然后等待”叫号“，但是呢这样的话CPU还是在忙等，因此在临界区耗时比较多的时候就不那么高效。


## Ticket Lock with yield()
```
typedef struct {
    int ticket;
    int turn;
} lock_t;

…

void acquire(lock_t *lock) {
    int myturn = FAA(&lock->ticket);
    while (lock->turn != myturn)
        yield();
}

void release(lock_t *lock) {
    lock->turn += 1;
}
```

即使这样的话还不是很高效，耗时比较如下：
- 使用yield: O(threads × time_slice)，耗时主要在spin等待上
- 不使用yield: O(threads × context_switch_time) ，耗时主要在上下文切换上

## Blocking Locks
- acquire()：使用系统调用阻塞当前线程并加入等待队列。
  - 使用的是park()系统调用
- release()：使用系统调用将等待队列里面的线程拿出来重新运行
  - 使用的是unpark()系统调用

park()和unpark()灵感来自于Solaris里面的lwp_part()与lwp_unpark()

```
typedef struct {
    int lock;
    int guard;  // 目的应该是保护lock变量和任务队列的
    queue_t q;
} lock_t;

void acquire(lock_t *l) {
    while (TAS(&l->guard, 1) == 1)  // guard只有两个值，只允许一个线程操作queue
        ;
    if (l->lock) {
        queue_add(l->q, gettid());
        setpark();  // setpark()通知系统我即将park()我自己
        l->guard = 0;
        park(); // blocked
    } else {
        l->lock = 1;
        l->guard = 0;
    }
}

 
void release(lock_t *l) {
    while (TAS(&l->guard, 1) == 1)
        ;
    if (queue_empty(l->q))
        l->lock=false;
    else
        unpark(queue_remove(l->q));
        // 为什么在这里没有使lock=false呢？
        // 是因为unpark之后线程会从park处继续，这样的话就可以直接利用lock，lock值没变，
        // 但是从逻辑上来说所有权已经归属于刚刚unpark出来的线程了        
    l->guard = false;
}

```

setpark()的作用：如果在setpark()和park()之间有一个unpark()调用，那么调用park()的线程并不会被阻塞，会立即返回。
