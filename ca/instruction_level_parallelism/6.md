# Hazards
在CPU流水线中下一条指令无法在下一个时钟周期内被执行，或者执行会导致结果出错。通用的解决方案是流水线“空泡”，即不执行，等待上一条执行完成再执行第二条
## Data Hazards
当表现出数据依赖性的几条指令在Pipeline不同阶段被执行时发生的危险
解决方案有以下几种：
1. 插入流水线空泡，为了提升效率可以在空泡阶段加入无关指令来执行
2. 使用Operand forwarding
3. 在乱序执行场景下，还可以使用Tomasulo算法进行寄存器重命名
### RAW
还没写完就去读

### WAW
还没写完就写

### WAR
还没读完就写

## Control Hazards
分支预测错误了，被预先执行的指令必须被取消

## Structual Hazards
计算单元不够用了

# 一致性模型
## TSO

如果分支和长延迟的指令会带来流水线气泡，那么能不能把这些气泡占据的处理器时间用来干有用的事情呢？为了达到这个目的，就需要引入乱序执行。乱序执行允许处理器将部分指令的顺序打乱，在执行长延迟指令的同时执行一些别的指令。历史上有两种方式来达到乱序执行的目的：软件的和硬件的。
# 实现方式
## 软件实现
软件的途径很好理解，就是通过编译器与体系结构的强耦合，在编译阶段就生成好无相互依赖，易于处理器调度的指令。在编译阶段进行指令重排又被称为静态指令调度，优点是软件实现可以更灵活（众所周知，软件什么都能干），通常软件也可以有足够的存储空间来分析整个程序，因此可以获得更优的指令排布。当然缺点也是显而易见的，由于编译器需要深入地了解体系结构相关的信息，如指令延迟和分支预测惩罚等，对可移植性造成了很大的困难。因此现代处理器更加常用的是硬件方式。

## 硬件实现
硬件方式主要是通过寄存器重命名来消除读—读和写—写假依赖。寄存器重命名就是对不同指令调用的相同寄存器使用不同的物理硬件存储，在写回阶段再对这些指令和寄存器进行排序，这样这些假依赖就不再是产生流水线气泡的原因了。注意，写—读依赖是真正的数据依赖，虽然像前递这样的技术可以降低延迟，但是并没有能够解决这种依赖的办法。现代处理器中也并非仅仅只有如16个通用寄存器和32个浮点寄存器等等，通常都有成百上千的物理寄存器在CPU的片上。寄存器重命名的算法最有名的便是Tomasulo算法，有兴趣的读者可以搜索一下。

硬件方式的优点在于降低了编译器的体系结构耦合度，提高了软件编写的便捷性，通常硬件乱序执行的效果也不必软件的差。而缺点在于依赖分析和寄存器重命名都需要耗费宝贵的片上空间和电力，但对于性能的提升却没有相应的大。因此，在一些更加关注低功耗和成本的CPU中，会采用顺序执行，如ARM的低功耗产品线，Intel Atom等。

# Meltdown漏洞
### 原理
```
 ; flush cache
 ; rcx = kernel address
 ; rbx = probe array
 retry:
  ; 产生中断信号
  mov al, byte [rcx]
  shl rax, 0xc
  jz retry
  mov rbx, qword [rbx + rax]
 ; measure which of 256 cachelines were accessed
```

1. 首先清空cacheline
2. 拿到内核地址，放入`rcx`寄存器中
3. 声明一个数组，大小为4096\*256字节大小（因为一次只能拿1B数据，所以256就可以hold住）
4. 使用`mov al, byte [rcx]`去访问内核数据，这个时候陷入内核态
   - CPU一边执行内核态的判断程序，一边依据乱序执行规则继续往下执行
   - 计算机内有多个寄存器，在执行`mov al, byte [rcx]`的时候虽然没有把值读进rax里，但是也读到了其他寄存器内，我们把它叫做X寄存器吧，如果后续指令没作废的话直接把X寄存器的值赋值给rax就好，后续指令作废的话不执行赋值就好，所以下面的指令看似是对rax的操作，实际上是对X寄存器的操作。这里的原理是这样的：C取决于B，B取决于A，A结果还没出来，B、C都被CPU执行完了。
   - `shl rax, 0xc`操作会把rax里的值放大4096倍，假设内核里的数据是x，那么左移12位之后就是x\*4096
   - 再去访问探测数组，访问第x\*4096个字节，这样的话x\*4096字节所在的64B都会被加载进cache
5. CPU终止此次非法访问，回到用户态
6. 遍历探测数组，计算访问延时，比如说第57\*4096个字节访问最快，那么内核里的数据就是57

### 疑问
1. 直接拿到的数据吗？

    并不是，是把在内核态的数据“藏”到cache中了，使probe_array[kernel_data]访问变快了

2. 为什么要乘4096？
    
    因为CPU一次不一定只拿一个cacheline，有可能拿多个，所以这个操作相当于把间距扩大了
    ![image](https://user-images.githubusercontent.com/56379080/145006192-b16dadf0-7037-44a4-b970-f85f74c4a57e.png)

3. CPU不是有内核态和用户态吗？怎么会拿到内核态的数据？

    没有直接拿到，利用了CPU的乱序执行特性

4. 一次能拿多少数据？

    一次只能拿1B的数据
