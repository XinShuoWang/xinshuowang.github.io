**阅读之前建议先看完第一篇文章《Free Lunch是什么意思？》**

IPC：Instruction Per Second，每秒指令数。早期CPU的IPC可能只有0.25，因为需要4个时钟周期才能完成一条指令；单流水线CPU的IPC可以到1，因为每秒都有指令输出结果，每条指令执行时间不变，但是总体吞吐提升了；多发射CPU的IPC可以大于1，因为每个时钟周期有多条指令产生结果。

# 早期CPU
最早的CPU很简单，具体的执行过程都在《CPU执行指令》一文之中，读完之后你将知道一条汇编指令是如何指示Control Unit做完计算的。

# 单流水线CPU
早期执行一条指令大概可以分为这几个流程：
- Fetch
- Decode
- Execute
- Access Memory
- Write Back

![顺序执行](https://user-images.githubusercontent.com/56379080/144983936-d4eee5fb-1c89-4d7f-be46-cef0a5a5a1c0.png)

观察上图可以发现，计算部件大部分时间都是空闲的，IPC在0.25左右，所以为了提高部件利用率人们就采用了如下图所示的流水线技术，每条指令的执行时间没变，但是IPC却到了近乎1的地步，吞吐率大大提高了。

![流水线执行](https://user-images.githubusercontent.com/56379080/144983607-c0f0a7ab-b3c2-4e36-b779-9d7b2f405f64.png)

## 分支预测技术
在没有分支预测技术的时候，如果有一条跳转指令在前面正在执行，后面的指令都不能预先加载，都需要等待分支跳转指令执行完毕才能知道具体加载哪个分支的代码，这就造成了一个问题：流水线产生了空泡，像下图这样：

![流水线空泡](https://user-images.githubusercontent.com/56379080/144983464-5c4f370c-d128-4244-8745-0419baa26664.png)

因为不想让流水线出现“空泡”，想尽量塞满流水线，所以就有了分支预测技术来提前将指令加载并运行（分支预测失败就要冲刷流水线），分支预测就是在分支指令还没执行完毕的时候，根据历史信息来判断可能性最大的分支，从而预先加载指令填满流水线。

## 乱序执行
即使使用了分支预测技术也不一定能保证完全填满CPU，因为可能有一些指令依赖前项的执行结果，这时候就要使用乱序执行这个技术，这个技术允许一定程度的流水线冒险来提高效率，多线程问题根源之一的有序性就是被这样打破的。

## SMT同步多线程
分支预测与乱序执行都是在一个线程内部进行优化的，而线程与线程之间一定是可以独立执行的（同步点也算一个线程内的），而且线程之间完全有可能如下图一样具有互补关系

![image](https://user-images.githubusercontent.com/56379080/145013953-13ebd0cf-ab10-437c-a637-5bff881bfeeb.png)

下图是Intel SkyLake架构图，一共8发射，但只有4个运算单元。

![image](https://user-images.githubusercontent.com/56379080/145015017-62d3b7fb-e352-4e3b-8ab3-9a64116e095b.png)

从硬件角度来说，同步多线程的实现需要将所有与运行状态有关的结构数量都翻倍，比如寄存器，PC计数器，MMU和TLB等等。幸运的是，这些结构并不是CPU的主要部分，最复杂的译码、分发器、运算器和缓存都是在两个线程之间共享的。

在计算密集型应用中，不打开SMT反而会更好一点，因为SMT进行切换也需要开销。

# 超标量CPU
## 多发射
因为CPU内部整数的运算器和浮点数的运算器以及其它的的一些ALU互相之间都是没有依赖的，所以就出现了多发射和超标量处理器。多发射的意思是处理器每个周期可以“发射”多于一条的指令，比如浮点运算和整数运算的指令就可以同时执行且互不干扰。为了完成这一点，取指和译码阶段的逻辑必须加强，这就出现了一个叫做调度器或者分发器的结构，就像这样：

![image](https://user-images.githubusercontent.com/56379080/145030057-a5105d0f-d5cb-461f-989d-e00ed375756a.png)

现在不同的运算有了不同的“数据通路”，经过的运算器也不同。因为不同的运算器内部可能也分不同的执行阶段，于是不同的指令也就有了不同的流水线深度：简单的指令执行得快一些，复杂的指令执行得慢一些，这样可以降低简单指令的延迟（我们很快就会涉及到）。某些指令（比如除法）可能相当耗时，可能需要数十个周期才能返回，因此在编译器设计中，这些因素就变得格外重要了。可以看到这里面时钟频率被分的更细了。

![image](https://user-images.githubusercontent.com/56379080/145030473-844146ea-47b4-4119-a515-eedd0b2d40cc.png)


## RISC-V BOOM
现代CPU一般都是超标量的，以RISCV-BOOM为例，流程已经扩展到10级左右，分别为：
- Fetch：从内存中取出Instruction然后压入到Fetch Buffer中，Fetch Buffer是一个队列数据结构。分支预测也发生在这个阶段，根据当前指令结合分支预测决定该去哪里取指令。
- Decode：在Decode阶段，解码器从Fetch Buffer中读取指令，然后产生对应的Micro-Op(s)，也叫UOP。
- Rename：ISA里面的逻辑寄存器将被重命名成物理寄存器，其实就是根据映射关系决定该用哪一个寄存器。
- Dispatch：UOP被分发到不同的发射队列里面。
- Issue：UOP等到时机成熟就被发射出去执行，这是在pipeline中乱序执行的开始。
- Register Read：UOP读取寄存器的值
- Execute：来到执行阶段，Memory操作在这个阶段完成地址计算，然后把这个地址存放到Load/Store Unit里面。
- Memory：Load/Store Unit有3个队列：LAQ(Load Address Queue)、SAQ(Store Address Queue)、SDQ(Store Data Queue)，会从LAQ中拿出地址进行Load操作，Store操作会在commit阶段提交，通常情况下只有当store操作的地址不在SAQ中且数据不在SDQ中时才能提交。
- Writeback：ALU操作和load操作都需要写会到寄存器中。
- Commit：Reorder Buffer（ROB）一直追踪着pipeline中每个指令的状态，当ROB头部空闲的时候就可以提交这个指令了，以Store操作为例，ROB会让在SAQ和SDQ头部的元素把数据写入内存。

![RISCV-BOOM架构图](https://user-images.githubusercontent.com/56379080/145028367-0a864727-ef02-4593-b880-ac4066a57c3d.png)

## EE领域专业名词解释：
- Front-end：实现取指阶段和分支预测功能的部分
- Back-end：实现从Dispatch到WriteBack阶段功能的部分



