# 技术简介
都是可以减少解释执行开销的操作
## 向量化
next()函数不是只返回1个tuple，而是返回一个block，block里面含有100~10000不等的tuple

好处：
1. next()被调用的次数少了
2. 编译器可以很好的优化对一批数据进行处理的操作
	- 循环展开
	- 自动SIMD
3. 没有了函数调用，分支预测更成功
4. 现代CPU的多级流水线可以更好的发挥作用


## JIT
在收到一个Query的时候，根据这个Query生成一段代码，使用JIT之后直接得到一段可执行程序（在内存中），执行这段程序就可以得到结果

**怎么生成的代码？生成什么样的代码？**

[![IThyPU.png](https://z3.ax1x.com/2021/11/18/IThyPU.png)](https://imgtu.com/i/IThyPU)
[![ITh6GF.gif](https://z3.ax1x.com/2021/11/18/ITh6GF.gif)](https://imgtu.com/i/ITh6GF)

其实在实际使用中，几乎不需要重写算子，只需要把算子实现编译成LLVM IR，然后就可以在运行中调用这些IR来生成可执行程序

**在TP里使用JIT效果会好吗？**

不一定，因为TP只获取很少的行；如果在TP中使用JIT的话，可以把生成的可执行内存缓存起来，每次只需简单修改条件就可以再次执行

好处：
1. 更小的解释开销（没有了虚函数调用）
	- 虚函数的开销主要不是在分支预测上，因为CPU有二级自适应分支预测器来预测间接寻址
	- 主要开销在预测失败之后的流水线冲刷的代价
2. 更好的指令局部性
3. 如果搭配向量化执行模型还可以应用SIMD指令来优化


# 比较
## Projection
```
SELECT
    /* 4B                 1B               1B  */
    l_extprice * (1 - l_discount) * (1 + l_tax) 
    /*    根据数据范围：1B * 1B = 2B,  2B * 4B = 4B   */
FROM
    lineitem;
```
### 向量化实现
[![IThDaV.png](https://z3.ax1x.com/2021/11/18/IThDaV.png)](https://imgtu.com/i/IThDaV)

16个tuple来说，使用向量化操作的话理论上需要30条指令，实际需要60条指令（转换、对齐），非向量化操作需要16*16条指令，大概是向量化后指令的4倍
其中30的由来是这样的：30 = 22条load/store指令 + 8条SIMD指令 = （）+ （8bit加法 + 8bit减法 + 2个8bit乘法 + 4个32bit乘法）

### 向量化+编译执行
更少的load/store指令

[![IThBV0.png](https://z3.ax1x.com/2021/11/18/IThBV0.png)](https://imgtu.com/i/IThBV0)

### 火山模型+编译执行
（下图）黑菱形代表火山模型性能，黑星星代表编译执行的火山模型性能，大概是3倍左右（23 / 7）

### 总结
[![IThr5T.png](https://z3.ax1x.com/2021/11/18/IThr5T.png)](https://imgtu.com/i/IThr5T)

- SIMD-sht代表预设l_extprice不再是4B而是2B，能更多的放进SIMD寄存器里
- 性能最好的是使用编译执行与向量化混合的
- 使用向量化时的批大小不可以太大，否则会产生cache miss，上图曲线后期上升的原因就是cache miss
- 如果想使用较大的批的话可能要考虑混合向量化与编译执行（混合是指对map函数进行编译）的引擎（蓝线、紫线显示他们对L1 CacheMiss不敏感，但是对L2 CacheMiss敏感）

## Select
```
SELECT
    *
FROM
    table1
WHERE
    col1 < v1
AND
    col2 < v2
AND
    col3 < v3;
```

### 向量化执行
SIMD提供Selection Vector，选择原语也可以将选择向量作为参数，只对来自选择向量所指向位置的向量元素计算。

[![IThc24.png](https://z3.ax1x.com/2021/11/18/IThc24.png)](https://imgtu.com/i/IThc24)

### 编译执行
[![IThgxJ.png](https://z3.ax1x.com/2021/11/18/IThgxJ.png)](https://imgtu.com/i/IThgxJ)

### 总结
[![IThRM9.png](https://z3.ax1x.com/2021/11/18/IThRM9.png)](https://imgtu.com/i/IThRM9)

- 都使用向量化{一个使用branching， 一个不使用branching}，发现不使用branching的效果要好，因为有selection vector的支持；当有if且分支选择性不明显的时候就会阻碍CPU填满整个流水线，从而导致性能不高，最好是将控制依赖转化为数据依赖。
- 编译执行不如向量化且无branch的性能
- compute all性能差的原因：计算了所有的情况，即使可以直接“短路”的
- 建议是在第一个谓词上使用if，其他的谓词使用数据依赖（使用数据依赖的时候编译器会优化成向量化）

## HashJoin
```
SELECT
    build.col1, build.col2, build.col3
WHERE
    probe.key1 = build.key1
AND
    probe.key2 = build.key2
FROM
    probe,build;
```
### 数据组织格式
NSM：行存
DSM：列存，不过需要把主键和数据组合在一起存储

[![IThfq1.png](https://z3.ax1x.com/2021/11/18/IThfq1.png)](https://imgtu.com/i/IThfq1)


### 向量化执行
[![IThWrR.png](https://z3.ax1x.com/2021/11/18/IThWrR.png)](https://imgtu.com/i/IThWrR)

### 部分编译执行
将fetch部分的代码进行了编译

[![ITh4Vx.png](https://z3.ax1x.com/2021/11/18/ITh4Vx.png)](https://imgtu.com/i/ITh4Vx)

- TLB：又称快表，一种缓存，用来完成逻辑页到物理页映射的缓存
- 向量化有大量随机访问（每一列单独拿），会导致TLB失效或者cacheline失效，对cache不友好
- Compile NSM效果更好：每次从一个地方拿上来所有的数据，有更好的数据局部性


### 全量编译执行
[![ITh5a6.png](https://z3.ax1x.com/2021/11/18/ITh5a6.png)](https://imgtu.com/i/ITh5a6)
- 效果不如向量化+fetch部分编译执行
- 如果一个load指令被stall了，CPU可以去猜测下面需要进行预加载的数据，这样可以获得更大的带宽和更低的时延
- 向量化和部分编译都可以轻松打满CPU
- 全编译无法打满CPU，因为依赖于while(pos = ...)部分返回Flase才不会出现Random Access，所以时延是向量化方法的4倍

### 结论
[![IThIIK.png](https://z3.ax1x.com/2021/11/18/IThIIK.png)](https://imgtu.com/i/IThIIK)

- 随着Hash Table的增大性能会急剧下降，因为TLB失效和Cache Miss都会出现
- NSM相比与DSM有更好的局部性，因为这里2个主键进行EQUAL JOIN，行存一下子可以把两列都拿到

[![IThTPO.png](https://z3.ax1x.com/2021/11/18/IThTPO.png)](https://imgtu.com/i/IThTPO)

- 符合JOIN条件的列越多成本也就越高，成本主要消耗在Fetch阶段
- NSM的局部性更好

[![ITh7GD.png](https://z3.ax1x.com/2021/11/18/ITh7GD.png)](https://imgtu.com/i/ITh7GD)

- 当bucket后跟的chain越长的时候，针对DSM数据组织格式的Fully Compiled方案性能最差，因为没有利用到并行内存读取的特点

# 结论
1. 最好是将向量化与Code Generation结合
	- 对Projection来说，编译执行提供更少的load/store，向量化提供更快地计算
	- 对Select来说，编译执行提供更少的计算代价（否则全都要计算，先做判断可以减少计算代价），向量化执行可以加快计算
	- 对于HashJoin来说，编译执行提供Cache友好的执行，向量化提供并行内存读取
2. 对火山模型来说编译执行收效甚微
3. 向量化的好处：
	- SIMD
	- 避免分支预测失败
	- 并行内存读取

# 缺点
1. 在使用SIMD的时候，CPU会降频，因此并不能简单使用Cycle/tuple来作为比较标准
