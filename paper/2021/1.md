最近由于要优化一个比较老的数据库的Hash Join算法，所以在读一些相关的论文；关于论文的选择方面，在CMU 15-721这门课上有一栏是Hash Join相关的，所以我也就直接读这里面的论文了，省了不少挑选论文的时间。这篇论文是目的是探索Hash Function与Hash Scheme的不同组合在不同Load Factor、不同数据分布（密集分布（1-n）、稀疏分布（在1-2^63-1中随机选择n个）、网格分布（将64位数据划分为8个块，每个块只在1-14之间生成随机数））、不同数据集大小等7个方面的情况下的性能表现。
我这篇文章只是简单说一下里面提到的Hash Function与Hash Scheme，对于实验以及实验结果不做解释。
如果想对实验有进一步的了解可以阅读论文，论文最后给了一个决策建议，你可以根据自己的应用需求进行有取舍的选择。

# 作者介绍
[![Jens Dittrich](https://z3.ax1x.com/2021/11/24/oi0v11.jpg)](https://imgtu.com/i/oi0v11)

一作应该是Jens Dittrich的学生,Jens Dittrich现德国萨尔兰大学教授，曾就职于苏黎世联邦理工大学，曾获VLDB 2014最佳论文奖。这个教授的组应该是做数据库中的Hash Join相关方向的，我已经看到了好几篇他们发的VLDB。这个老师在Youtube也有相关的公开课，大部分是英文的，感兴趣的可以去搜索一下。


# Hash函数
文中提到了4种Hash Function，分别是： 
- Multiply-shift 
- Multiply-add-shift 
- Tabulation-Hashing 
- MurMur hasing

## Multiply-shift
```h(x) = (x * z mod 2^w) div 2^(w-d)```，```w```是位宽，```x```是一个介于```0```到`2^w-1`之间的数字，`z`是一个介于`1`到`2^w-1`之间的奇数，hash table的大小是`2^d`。 

优势：
1. mod操作不用关心，因为在现有计算机中x*z如果导致溢出，那么效果就是`mod 2^w 2`. 冲突概率是`1/(2^(d-1))`

## Multiply-add-shift
`h(x) = ((x * a + b) mod 2^(2w)) div 2^(2w - d)`,其中`x`是一个`w`位的整数，`a`与`b`都是`2w`位的整数，hash table大小是`2^d` 当`x`是64位的时候，`a`与`b`需要为128位的数，这是很难实现的，所以我们仍然可以使用64位的计算。

## Tabulation-Hashing
步骤如下：
1. 把64位的数字按8位一组进行分组`{c1, c2, ... c8}` 
2. 创建8个表格，每个表格有两列，第一列是`0-255`，第二列是随机生成的值`{Ti[i]=random()%（2^64-1）}` 
3. `c1`是一个介于`0-255`之间的值，所以直接去`T1`表中拿到对应的随机值`{x=T1[c1]}` 
4. 依次进行8次，将8个结果进行XOR即可 

优势： 
1. 表大小是16KB，可以放入L1缓存，所以会非常快。

## MurMur hasing
示例代码：
```
uint64_t murmur3_64_finalizer(uint64_t key) {
    key ˆ= key >> 33;
    key *= 0xff51afd7ed558ccd;
    key ˆ= key >> 33;
    key *= 0xc4ceb9fe1a85ec53;
    key ˆ= key >> 33;
    return key;
}
```

# Hash Scheme
Hash Scheme我理解就是基于线性表做的一系列操作从而把数据放进数据结构里，方便O（1）的查找。
文中提到了5种Hash Scheme，分别是： 
- Linear Probing 
- Quadratic Probing
- Chained Hashing 
- Cuckoo Hashing 
- Roobin Hood Hasing

## Linear Probing
线性探测(LP)是开放寻址中最简单的冲突处理方案。哈希函数的形式如下:`h(k, i) = (h_(k) + i) mod l`，其中`i`表示第`i`个探测位置，`h_(k)`是一个辅助哈希函数。它的工作原理如下:首先，尝试插入一个键值对`<k, v>`，键k在最优情况下会在`T[h(k，0)]`Slot中，如果在开放寻址哈希表t中`T[h(k，0)]`已经被另一个具有不同键的项占用，就要循环探测连续的槽`h(k，1)， h(k，2)， h(k，3)， ...，`直到`h(k,i)`是空的，我们就把`<k,v>`此Slot中，我们将`<k, v>`的位移d定义为i，将所有项上的位移之和定义为t的总位移。我们可以看到，总位移是线性探测性能的度量，因为在查找过程中，较高的总位移意味着比较长的探测序列。 

LP的优势主要有以下两个： 
1. 较低的实现复杂度。 
2. 较好的Cache友好性

但是LP也存在一些问题：对删除的处理比较复杂，因为我们不能直接移除给定的数据项（如果直接移除将会把cluster截断，导致查询错误，cluster是探测序列中临近的被占用的Slot区域），一种处理方法就是使用TombStones，即“墓碑”。

## Quadratic Probing
Quadratic Probing（QP）是另一种比较流行的处理冲突的开放地址法，在QP中Hash Function是这样的```h(k,i)=(h_(k) + a * i + b * i ^2) mod l```，i与LP一样代表着探测轮次，l代表着Slot的大小，`a`与`b`都是一个常量。 如果表的容量l是2的幂，且`a = b = 1/2`，可以证明二次探查将在最坏情况中考虑表的每个Slot一次。也就是说，只要哈希表中有空槽，这个特殊版本的二次探测最终总会找到它们。 如果两个key在第一次就发生了hash冲突，那么之后每一次探测都会发生冲突。

## Chained Hashing
Chained Hashing是一种非常简单的冲突处理方法，其中表T的每个Slot（实现时一般使用数组）是一个指向条目链表的指针。在插入时，数据被附加到与哈希函数h下的键k对应的列表中，即`T[h(k)]`下。在查找阶段,需要在`T[h(k)]`指向的链表中进行查找即可。Chained Hasing是一个简单的和健壮的方法,被广泛应用在实践中,例如,在当前STL的std::unordered_map或Java的`java.util.HashMap`的实现中都是这种方法。 与开放寻址方法相比，Chained Hashing对于整数键来说性能和内存占用通常都不太好。这主要有两个原因: 
1. 链表所使用的指针会导致较高的内存开销（在64位系统中，一个指针占用8 Byte）。 
2. 使用链表会导致Cache Miss(即使是对于只有一个元素且没有冲突的槽)。

Chained Hasing还有两种变种，分别是ChainedH8与ChainedH24，ChainedH24做的改进是原来每个Slot只存放指向链表的指针，现在每个Slot里面都可以存放3个数据，这将减少Cache Miss。

## Cuckoo Hashing
Cuckoo hasing是另一种开放寻址方案，在其最初(也是最简单的)版本中，其工作原理如下:有两个哈希表`T0,T1`，每一个都有自己的哈希函数`h0`和`h1`。每个插入的元素p都存储在`T0[h0(p)]`或`T1[h1(p)]`中，但从不同时存储。当在插入阶段的时候`T0[h0(p)]`或`T1[h1(p)`]都有数据，那么就随机挑选一个表中的对应位置上的数据进行踢出，再给这个被踢出的数据重新找一个位置进行插入，Cuckoo Haing有一个移动次数上限，如果达到了要更换Hash函数，对所有元素进行重新Hash。 

Cuckoo Hashing的优势： 
1. 最多只需要两次探测即可找到值。 
2. 易于实现 
3. 性能基本与LP、QP相当。

## Robin Hood Hasing On LP
一般来说，Robin Hood的提出是基于这样的观察：交换cluster里面的KV对并不影响探测。 罗宾汉Hash，每个元素都附带上自己的distance信息，如果新元素的distance大于旧元素的distance，那么要给旧元素重新找位置，否则就继续往下探测、进行比较。


# 思考
1. 不同Hash函数对整型、字符串型等的效果是怎样的？我觉得字符串可以看做是实验里的grid分布，因为带有一定的范围性（ASCII可见字符是有范围的）
2. Mult是最佳的Hash函数，代价就是对于不同的数据分布方差可能比较明显。
3. 对于写一次读多次的场景来说，Robin Hood性能比较好，Roobin Hood Hashing通过牺牲1%-5%的峰值性能改变了LP的最坏性能。
4. chained hash与cuckoo hash都不适合写较多的场景。
5. 总的来说，Array-of-Struct比Struct-of-Array要优秀，这里要解释一下什么是AOS，什么是SOA，AOS就是把一块内存初始化为一个结构体的数组，详见例1，SOA是把一块内存初始化为一个结构体，详见例2。

```
// 例1
typedef struct person{
    char[8] name;
    char[1] sex;
} person;

char* data = new char[4*1024];
person* p = (person*)data;
// 例2
const int person_cnt = 100;
typedef struct persons{
    char[8 * person_cnt] name;
    char[1 * person_cnt] sex;
} persons;

// 便利每一个人的姓名
person.name[index * 8]
```

# 趣事
前面介绍了Hash Function与Hash Scheme，但是还有一点没有说明，那就是bucket的数目该怎样选择，在讲这件事情事情可以先讲一个小故事：在美国有一种蝉叫做“周期蝉”，它们每隔固定的周期就会大规模爆发一次，他们的周期为一个素数，17年。可以想一想为什么偏偏是17呢，不是15或者10或者其他数字呢？
自然界中，一般捕食蝉的为鸟或者其他动物，它们的爆发周期比较短，比如说是3年，如果蝉的周期为15年的话，每次蝉一出现就会碰上天敌的爆发（蝉的第2辈后代会碰上天敌的第5辈后代），这样的话不利于繁衍，而如果蝉选择17作为周期的话就只会在17*3=51年才会与天敌碰上一次，其余的都可以避开天敌从而繁衍下去。
应用到Hash函数里面也就有一点讲究了，如果bucket数目是素数，那么对`bucket_num`取余就会散布的非常均匀，这也不是说`bucket_num`不是素数就是什么大不了的事情，但是会在某些极端场景之下产生副作用，比如说：Hash Function会产生全是4的倍数的Hash Value，而`bucket_num`是32，那么将会有`3/4`的空间被浪费（只有第4、8、16、32个bucket被使用）。

# 参考文献
- [A Seven-Dimensional Analysis of Hashing Methods and its Implications on Query Processing](https://15721.courses.cs.cmu.edu/spring2018/papers/19-hashjoins/richter-vldb2015.pdf)
- [CMU 15-721课程主页](https://15721.courses.cs.cmu.edu/spring2020/schedule.html)
