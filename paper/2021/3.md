这是VLDB 2021的最新论文，主要讲述了在分析型数据库中怎样高效的使用部分Operator的结果来为下面的Query服务。我总结的这篇论文的两个主要贡献点：
1. 提供了Query间的正则化、匹配算法
2. 实现了Cache的生命周期提升算法以更好的优化后期查询


# 背景
## S3 Select是什么？
- S3 Select 是 Amazon S3 的一项功能
- 适用于以 CSV、Parquet 、JSON 格式存储的对象
- 只支持简单的谓词下推逻辑

## S3 Select怎么用？

[![Iflgb9.png](https://z3.ax1x.com/2021/11/16/Iflgb9.png)](https://imgtu.com/i/Iflgb9)

## 打算干什么？
- 现在很多数据库都支持以S3作为存储，有部分数据库（Greenplum）支持了S3 Select
- 打算把S3 Select返回的结果给缓存起来，这样就避免了计算与远程网络IO的双重开销带来的时延
- 但是如果仅仅只做“是否等于”的判断效果不会好，不如直接进行结果缓存，因此要做缓存复用：一个缓存块能被多个Query使用
- 更一般化的描述：Query Cache直接缓存结果，含有100%的计算量，Block Cache直接缓存数据块，含有0%的计算量，中间部分计算结果被浪费了，所以要缓存起来，用来弥合0%与100%之间的GAP

[![IflWU1.png](https://z3.ax1x.com/2021/11/16/IflWU1.png)](https://imgtu.com/i/IflWU1)

## 典型场景
```
// 第1条SQL
SELECT * FROM test WHERE b < 40;

// 第2条SQL
SELECT * FROM test WHERE a > 30 AND b < 40;
```
先执行第1条SQL再执行第2条SQL的情况下，第2条SQL会时延会缩短，因为只需对第1条SQL的Filter算子的扫描结果进行再一次Filter即可，而不必对整个table进行Filter

## Related Work
File or Block based cache
Databricks Delta Cache、Alluxio、Snowflake Cache Layer只是以Page或者Block粒度来缓存（无计算）

### Materialized View
1. 手动介入来创建
2. 物化视图实现起来比较耗时
3. 在优化器里需要决定使用什么物化视图可以满足query比较困难

### Semantic Cache
1. 直接缓存结果
2. 之前有工作想把semantic cache划分为region来管理，但是开销非常大：访问一个重叠的region会导致region的切分和cache file的重写。
3. 还有一种Chunk-based semantic caching，不过需要人为定义chunk

### Intermediate Result Cache：
1. 之前有一些技术利用了时间局部性来做缓存（只对concurrency的请求成立）
2. 也有一些工作在中间结果缓存上做的很好，但是都没有Crystal集成到DBMS中方便。

### Mid-tier Database Cache（中间件缓存）
1. 需要人力参与定义view

### Crystal优势
1. 对DBMS不需要修改就可以集成，可插拔的缓存。
2. 关注于存储层，可以实现最大程度的DBMS间复用（Spark和Greenplum可以用一套缓存）。
3. 可以根据策略（策略可定制）自主选择cache的东西。


# 设计
## API
- 因为支持S3 Select，所以不会只简单的把文件从远端下载下来使用，Crystal从DBMS接收带谓词下推的请求，类似SELECT name, age FROM test WHERE age > 20 AND age < 35;
- Crystal将请求转化为AST并序列化到字符串里面，类似 and(gt(age, 20), lt(age, 35))

## Transformation

[![IflHDH.png](https://z3.ax1x.com/2021/11/16/IflHDH.png)](https://imgtu.com/i/IflHDH)

- 如果只是以上面序列化后的AST为Key，返回的文件为Value进行缓存，意义不大，因为只有相同的查询才会复用这块缓存，因此要进行正则化。
- 上图就是对一个请求进行等价变换（否定下推、德摩根定律、否定推入谓词、否定范式转换为析取范式）后的形态
- 这时一个请求会被拆分成若干个超矩形（如上图的黄色与粉色两个限定就可以组成两个超矩形），若干个超矩形的析取被称为Region
- 不是所有的都能转化为超矩形，例如isNull

## Region Matching

[![IflLVA.png](https://z3.ax1x.com/2021/11/16/IflLVA.png)](https://imgtu.com/i/IflLVA)

Region由超矩形组成，超矩形的匹配算法（a，b）：
- a比b在相同列的上的限制条件更严格
- 没有谓词相对于有谓词来说限制是更宽松的。

Region匹配算法，其中conjunction可以理解为超矩形：

[![If1CrQ.png](https://z3.ax1x.com/2021/11/16/If1CrQ.png)](https://imgtu.com/i/If1CrQ)

上图就是一个Query和两个Region匹配的可视化展示

## Request Matching

[![If16Rf.png](https://z3.ax1x.com/2021/11/16/If16Rf.png)](https://imgtu.com/i/If16Rf)

匹配策略：
1. 最好的情况下还是一个Region就能满足要求
2. 否则Crystal就会去尝试满足单个的超矩形，但这有可能还需要额外的reduce操作，比如A和B可以满足一个Query，但是A和B区域有重叠但不完全相同，就需要一遍reduce操作进行去重


当找到1个Region是请求的Region的超集怎么办？
对Region进行切割后返回，以下图为例，只想要黄色的谓词代表的数据，就需要遍历Region，判断每条结果属于哪个超矩形。

[![If17WV.png](https://z3.ax1x.com/2021/11/16/If17WV.png)](https://imgtu.com/i/If17WV)
[![If1oiq.png](https://z3.ax1x.com/2021/11/16/If1oiq.png)](https://imgtu.com/i/If1oiq)


为什么不以超矩形为基本单位进行请求、缓存、匹配？

[![If1TJ0.png](https://z3.ax1x.com/2021/11/16/If1TJ0.png)](https://imgtu.com/i/If1TJ0)

- 超矩形在一个Query中最多可能有2^N个，数量过于庞大
- 超矩形之间重叠的可能性很大，如果使用超矩形为粒度容易造成时延增加和缓存空间浪费


当有多个Region的组合满足要求时怎么选择？
使用贪心法进行匹配，对于多个Region组成的待选列表，每次都从中选择一个能覆盖最多超矩形的Region然后进行reduce

[![If3EeH.png](https://z3.ax1x.com/2021/11/16/If3EeH.png)](https://imgtu.com/i/If3EeH)


## Cache Optimization
Requested Region Cache && Oracle Region Cache
Requested Region Cache：用来存放近期处理过的Region
Oracle Region Cache：负责捕捉负载的长期特征，内容来自RR Cache

### 背包问题
根据{策略}可以把RR Cache中的Region升级到OR Cache
策略：在一定的缓存大小下，缓存哪些Region将会最节省流量

常规解法是DP，但是DP应用在这里会有两个问题：
1. 规模太大，时空复杂度过高
2. DP解题的基础是最优子结构，但在这里最优子结构并不存在
	a. 为了解决重复问题，只能有一个Region拿到Single History Element的收益
	b. 决定哪个Region拿到这个收益是个问题

因此使用贪心算法近似求解
1. 使用效费比b/w来进行排序，b是如果缓存此Region会节省的网络流量，w是空间消耗
2. 按照效费比从高到低进行选择

[![If3FyD.png](https://z3.ax1x.com/2021/11/16/If3FyD.png)](https://imgtu.com/i/If3FyD)


### Region Augmentation
为了预测将来要访问的区域，OR Cache需要泛化，如果决策的候选集合仅由所见的历史元素组成，则OR Cache将过拟合，因此需要做数据增广，以包括未见区域。
大概思路：
1. 对所有Region两两进行Enlarge操作，Enlarge其实就是合并两个在同一个谓词上相邻的Region，比如一个Region是在X谓词上的限定是[10, 50]，另一个Region在X谓词上的限定是[80, 120]，就可以把这两个合并起来组成[10, 120]
2. 每个Enlarge之后的Region都有一个QualityValue和SizeSavingValue，QualityValue衡量的是包含Region的个数，SizeSavingValue表示合并之后节省的空间数量
3. 根据QualityValue进行排序，把排名靠前的加入候选集
4. 有当新Region不能用现有Region表示且其大小开销小于定义的最大大小或节省的大小大于原Region时，我们才会添加新区域。

[![If3iQO.png](https://z3.ax1x.com/2021/11/16/If3iQO.png)](https://imgtu.com/i/If3iQO)


## 实现的细节
1. Region在磁盘上的存储使用Parquet格式，内存中使用Apache Arrow格式
2. 使用Gandiva引擎进行Filter等计算操作，Gandiva引擎是针对于Arrow格式特别研发的计算引擎，会使用LLVM生成代码来加速计算。
3. 大量使用并行技术、Lock-Free技术

# 实验
主要是在spark上测试性能，在greenplum上测试通用性

## Cache Strategy
- vilion图一共3股蓝线，分别代表25%，50%，75%分位数，红点代表均值
- 使用数据集20%大小的缓存空间
- 多种缓存粒度、
    - 无缓存
	- 文件缓存
	- RR缓存
	- OR缓存
- 多种缓存置换策略
	- LRU
	- LRU-k
	- 背包的DP解法
	- 背包的贪心解法

[![If3btI.png](https://z3.ax1x.com/2021/11/16/If3btI.png)](https://imgtu.com/i/If3btI)
[![If3HAA.png](https://z3.ax1x.com/2021/11/16/If3HAA.png)](https://imgtu.com/i/If3HAA)
[![If3qht.png](https://z3.ax1x.com/2021/11/16/If3qht.png)](https://imgtu.com/i/If3qht)

结论：
1. a图与b图：背包贪心解法优于其他缓存替换策略
2. c图：OR能很好地捕捉到长期特征

## Block Cache
使用Crystal与Alluxio（Block Cache的代表）、File Cache作比较。

[![If3T7d.png](https://z3.ax1x.com/2021/11/16/If3T7d.png)](https://imgtu.com/i/If3T7d)

在进行过预热之后，不同缓存大小下不同缓存粒度对时延的影响
Alluxio一开始甚至不如不加缓存，只有在缓存空间很大时才能追得上Crystal

[![If3o0H.png](https://z3.ax1x.com/2021/11/16/If3o0H.png)](https://imgtu.com/i/If3o0H)

当缓存容量很大的时候，File级别和块级别缓存可以很快达到最佳性能
Crystal可以在短时间内学习到负载的特征

[![If3O9P.png](https://z3.ax1x.com/2021/11/16/If3O9P.png)](https://imgtu.com/i/If3O9P)

使用突发负载、规律性负载组合查询，RR/OR的结合效果最好


[![If8YuD.png](https://z3.ax1x.com/2021/11/16/If8YuD.png)](https://imgtu.com/i/If8YuD)
[![If8dUA.png](https://z3.ax1x.com/2021/11/16/If8dUA.png)](https://imgtu.com/i/If8dUA)

LRU适应性比较好，可以很快适应负载变化，OR-Kdp解法适应的比较慢，最优的是OR-Kg

[![If8NHH.png](https://z3.ax1x.com/2021/11/16/If8NHH.png)](https://imgtu.com/i/If8NHH)

集成进Greenplum做了这个实验，证明了Crystal良好的通用性


## TPC-H
[![If8tDe.png](https://z3.ax1x.com/2021/11/16/If8tDe.png)](https://imgtu.com/i/If8tDe)
[![If8aEd.png](https://z3.ax1x.com/2021/11/16/If8aEd.png)](https://imgtu.com/i/If8aEd)

a图是使用zipfan分布生成的Query的执行时间的概率分布，可以看出大部分都在5秒以内
22条SQL的执行时间如b图所示，提升并不明显（平均性能提升20%），主要是因为TPC-H的瓶颈在JOIN

## Microbenchmark
[![If8w4I.png](https://z3.ax1x.com/2021/11/16/If8w4I.png)](https://imgtu.com/i/If8w4I)

a图主要描述RR Cache：开销主要来自下载文件、Spark计算，匹配的开销可以忽略不计
b图和c图主要描述OR Cache：b图展示Refresh Latency，c图展示计算开销，LRU算法经常下载一些文件，随后就将其淘汰，所以downloading时间比较多

[![If8BCt.png](https://z3.ax1x.com/2021/11/16/If8BCt.png)](https://imgtu.com/i/If8BCt)

网络开销较小

[![If8D8P.png](https://z3.ax1x.com/2021/11/16/If8D8P.png)](https://imgtu.com/i/If8D8P)

Theta：不同的Theta变化不大，但使用贪心解决的方法最优，Theta是zipfian的参数，越大则头部效应越明显
Cache Size：贪心算法工作的很正确，即使只有很小的Cache空间也可以工作的很好
要存最近多少个历史meta信息？：小于64的话对性能有影响，很大的话对突变负载适应较慢
