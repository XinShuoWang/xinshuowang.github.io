各位同学大家好今天我将给大家介绍数据库查询模块相关的内容
![幻灯片1](https://user-images.githubusercontent.com/56379080/174482707-3c07b153-b6be-4208-bb67-ea3f706f3b8b.PNG)

首先我们需要知道查询模块具体是干什么工作的，来看这张图片，从大的方向上来说查询模块接受声明式查询语言SQL然后输出查询结果，具体的来说，SQL在进入到数据库之后首先经过词法语法分析器，在这里String类型的SQL会被解析成计算机可以理解的形式即逻辑查询计划，然后逻辑查询计划被送入查询优化器中，在这里会进行很多基于关系代数的等价变换、基于代价的物理算子选择等操作，然后查询优化器模块会输出物理查询计划供查询执行模块使用，查询执行模块会调用底层存储引擎的接口把数据经过处理之后返回给客户端，这就是一条SQL在数据库中的大致流程，下面我将按照上面这张图的划分具体讲一下词法语法分析、查询优化、查询执行的实现。
![幻灯片2](https://user-images.githubusercontent.com/56379080/174482723-d5acd1fd-95f8-4bb6-97fe-383ede26f16f.PNG)

首先是词法语法分析器模块，这一步主要的目的就是把输入的String类型的SQL应用编译相关技术解析为计算机可以理解的数据结构，大家可以看到这张图片里面展示的就是这样的操作步骤，更具体的步骤是这样的，SQL会首先经过词法分析器，词法分析器会把SQL切分成Token，这里的Token可以理解为一个一个单词，然后这些Token会被输入到语法分析器，语法分析器会对这些内容进行分析，如果不符合语法规则在这里就会报错，如果符合语法规则的话会被解析成语法树的形式。
![幻灯片3](https://user-images.githubusercontent.com/56379080/174482728-80878449-7920-4f47-9903-2f321a239b84.PNG)

下面讲一下词法语法分析器在常见的数据库中的具体实现，首先是比较常见的MySQL、PostgreSQL、OceanBase数据库都是采用Flex+Bison的解决方案，其中Flex是词法分析器，Bison是语法分析器，具体的实现可以去数据库源码里面寻找l和y结尾的文件去看一下使用方式，CK的话使用的是自己写的词法语法分析器，具体原因在源码模块提到是因为历史原因，具体地来说这个模块在业内的工作重点就是做SQL兼容性，比如OB就在做Oracle的语法兼容。
![幻灯片4](https://user-images.githubusercontent.com/56379080/174482731-325ad148-423a-451a-bd84-9d84c35739c0.PNG)

讲完了词法语法分析器模块我们就来到了查询优化器模块，这个模块非常的重要，甚至直接决定了一个数据库的性能体验，查询优化模块具体的工作内容可以用一句话来概括：使用统计信息估计出待处理行数，然后使用代价模型从枚举出来的所有计划中选择代价最小的，这一句话包含了查询优化模块的具体组成部分，分别是统计信息模块、代价估算模型模块、枚举引擎模块，每个模块面临的挑战也都五花八门，首先介绍统计信息模块面临的挑战，①统计信息是通过采样搜集，所以必然存在采样误差。②统计信息搜集是有一定滞后性的，也就是说在优化一个SQL查询的时候，它使用的统计信息是系统前一个时刻的统计信息。③选择率计算一直以来都是数据库系统的难点，学术界和工业界一直在研究能使选择率计算变得更加准确的方法，比如动态采样，多列直方图等计划，但是始终没有解决这个难题，比如连接谓词选择率的计算目前就没有很好的解决方法。
大家估计模型方面也面临很多挑战与难题，目前主流的数据库系统基本都是使用静态的代价模型，比如静态的buffer命中率，静态的IO Response Time，但是这些值都是随着系统的负载变化而变化的。如果想要一个非常精准的代价模型，就必须要使用动态的代价模型。
枚举引擎同样也有许多困难与挑战，最大的挑战当属搜索空间过大，尤其是还要在考虑到等价计划、不同算子的物理实现方式、分布式执行的基础上高效地枚举执行计划，这就使得搜索空间的搜索变得更加的庞大。
![幻灯片5](https://user-images.githubusercontent.com/56379080/174482736-d9dda2e7-087a-48d7-b98f-e0657df60913.PNG)

接下来我将把查询优化根据工作内容的不同拆分成很小的几个子模块来介绍，查询优化子模块包括通信信息收集模块、代价估计模块、枚举引擎模块三个子模块，最后还将介绍超多表JOIN的情况下的优化和在现在比较常见的ShareNothing数据库中如何进行对计划进行涉及到分布式执行相关的优化
![幻灯片6](https://user-images.githubusercontent.com/56379080/174482743-c5eff77e-e285-4ad0-8b03-acd599b2c6db.PNG)

数据库统计信息模块需要统计的信息有很多，包括但不限于表的总行数、列的分布情况、列中等于某个值的数据行数、Null 值的个数、行平均长度、Number of Distinct Value，下面我将主要讲统计信息模块对列的数据分布、列中等于某个值的数据行数、Number of Distinct Value这三个信息的收集处理策略。
![幻灯片7](https://user-images.githubusercontent.com/56379080/174482747-b635a16b-206f-4ec9-8292-6d3dc65ef571.PNG)

在具体的介绍统计收集信息之前，我们还需要了解抽样算法，因为数据库中数据量有可能很多，所以不能使用全量的信息进行决策，有的时候还需要对数据做排序等比较耗时的操作，这样的话就更不能使用全量数据，否则会导致影响整个线上系统的运行
抽样算法属于空间亚线性算法，空间亚线性算法的定义是这样的：由于大数据算法中涉及到的数据是海量的，数据难以放入内存计算，所以一种常用的处理办法是不对全部数据进行计算，而只向内存里放入小部分数据，仅使用内存中的小部分数据，就可以得到一个有质量保证的结果。在抽样算法中最常用的当属水库抽样算法，水库抽样算法解决的是这样一个问题：输入一组数量未知的数据，最后输出这组数据的k个均匀抽样，水库抽样算法的伪代码描述参见右图，算法可以这样理解：蓄水池（水库）的容量为k，对于n（n>k）个元素，如果第i个元素（i从1逐渐递增至n）以k/i的概率决定是否将它放入蓄水池，当i=n时，蓄水池中存放的是n个元素的均匀抽样，每个数字最终被存在数组中的概率相等，为k/n。这里证明就不给了
![幻灯片8](https://user-images.githubusercontent.com/56379080/174482752-2977d3de-09e6-4a93-96be-07af5a7cba7e.PNG)

接下来要介绍的是Count-Min Sketch算法，这个算法是一种可以用来估计等值查询数量的算法，而且可以提供很强的准确性保证，这个算法的过程是这样的：使用d个hash函数，每个hash函数的取值范围都在[1,w]内，从而可以组成一个d * w的二维数组。对于每个元素K，分别使用d个hash函数对k进行hash操作，得到d个mapped counters，然后对它们全部增加1，然后查询的时候走的是这样的流程：首先使用d个hash函数对元素k进行hash操作，得到d个mapped counters，然后计算这d个mapped couters的最小值就可以得到元素k的大概出现次数。
在数据库里一般是分别对每一列进行统计信息的收集，在进行完CM Sketch算法之后，我们就可以在处理等值查询的时候估计到这个等值查询涉及到多少行，从而进行正确的代价计算
![幻灯片9](https://user-images.githubusercontent.com/56379080/174482760-2f220b0f-2f88-4f0e-9fd8-40f72040188c.PNG)

接下来要介绍的是利用直方图来统计，直方图是一种对数据分布情况进行描述的工具，它会按照数据的值大小进行分桶，并用一些简单的数据来描述每个桶，比如落在桶里的值的个数。大多数数据库都会选择用直方图来进行区间查询的估算。
在这里我们主要使用的是等深直方图而不是等宽直方图，在图中左边是等宽直方图，右边是等深直方图，相比于等宽直方图，等深直方图在最坏情况下也可以很好的保证误差，
等宽直方图最大的缺陷是在数据频次较高的桶中统计信息不够清晰，比如在桶 [55, 60] 中，我们只知道它的总频次是40，却不知道是55、56、57、58、59各出现了8次，还是55出现了36次而其他值都只有一次。因此，当桶数量远小于列中 distinct value 数量、单个桶中 distinct value 过多且分布不均时，等宽直方图很有可能做出错误的估算并影响优化结果。
![幻灯片10](https://user-images.githubusercontent.com/56379080/174482767-7db937b0-27ac-473e-a9b8-72baae2ff518.PNG)

接下来介绍Number of distinct Value统计信息的收集，NDV信息的收集主要使用Linear Count算法，算法的流程如图所示，其实就是对bitset不断置位的过程
![幻灯片11](https://user-images.githubusercontent.com/56379080/174482770-5ba7b7c0-77eb-427d-824d-60e3257a04c0.PNG)

当统计信息收集完成之后就来到了代价模型计算阶段，代价模型主要包含4个方面的代价，分别是CPU消耗、内存消耗、IO消耗、网络开销等等，这里的估计模型是很粗略的，现实中还会更细致的划分，比如对于IO来说还有顺序IO和随机IO的区别
以HashJoin为例，HashJoin的CPU消耗是这样的，每个Probe操作的CPU消耗 乘上 Probe的数据量就得到了Probe阶段的CPU消耗情况，这里的Probe操作CPU消耗是个大概的值，比如如果是开放地址法实现的HashTable，那么消耗的CPU就是平均复杂度乘以比较函数的CPU消耗次数，HashJoin的内存消耗主要是HashTable的内存消耗
![幻灯片12](https://user-images.githubusercontent.com/56379080/174482771-bef6bed7-382b-4ee5-b103-3fa0745508b2.PNG)

现在介绍了统计信息模块，代价模型，有必要回顾一下查询优化模块的具体工作内容：使用统计信息和代价模型，从枚举出来的所有计划中选择代价最小的，我们还缺少最后一步，就是计划的枚举引擎，枚举引擎的目的是为了穷举出所有的计划，然后输入给代价模型，这样就能获得执行代价最小的执行计划给执行引擎去执行，
枚举引擎有两种流派的实现方式，分别是Bottom-Up类型优化器和Top-Down类型优化器，Bottom-Up类型优化器的代表之作是System R里面实现的优化器，它将查询优化分为逻辑优化和物理优化两个阶段，逻辑优化根据规则对执行计划做等价变形，物理优化则根据统计信息和代价计算将逻辑执行计划转化为能更快执行的物理计划，System R优化器有两个缺点，第一个缺点是扩展性不好。每次添加优化规则都需要考虑新的规则和老的规则之间的关系，需要对优化器非常了解的同学才能准确判断出新的优化规则应该处在什么位置比较好。另外每个优化规则都需要完整的遍历整个逻辑执行计划，添加优化规则的心智负担和知识门槛非常高。
第二个问题是搜索空间有限。搜索空间一方面因为优化规则难以添加导致比较狭小，另一方面，逻辑优化要求该优化规则一定在各个场景下都有收益才行，但在数据库面临的各种场景中，总有一些优化规则在某种数据分布下有收益，在另一种数据分布下没有收益，需要根据数据的分布估算代价来判断是否启用这些优化规则，因为这个原因，进一步导致一些优化规则不能添加到这个搜索框架中，或者添加后需要人工的通过开关来开启或关闭该优化规则。
![幻灯片13](https://user-images.githubusercontent.com/56379080/174482774-fa9ec729-5100-4ffa-a7df-8ef8a09967bf.PNG)

下面给出了System R优化器的大概工作步骤
![幻灯片14](https://user-images.githubusercontent.com/56379080/174482775-df21373c-145e-4700-8c9d-b5206858e0b6.PNG)

这边是System R优化器的一个工作示例
![幻灯片15](https://user-images.githubusercontent.com/56379080/174482778-7fdf7c3f-170c-472d-9461-1d34fbace4e6.PNG)

为了解决System R优化器的问题，后续就诞生了Volcano/Cascades类型的优化器，这种优化器的查询优化只有一个阶段，只不过会有两种规则，分别是Transformation Rule和Implementation Rule，优化器会应用这两种规则不停枚举计划，从而找到最优的物理执行计划
![幻灯片16](https://user-images.githubusercontent.com/56379080/174482781-5e7f3dec-657c-46ec-b8ed-48d34485b5d9.PNG)

下面介绍一下Volcanno/Cascades优化器的具体实现，Volcanno/Cascades优化器里面有2个比较重要的概念，分别是Expression和Group概念，Expression对应于数据库里的算子，它有0或多个input expression，Group是一组逻辑上等价（对数据处理效果相同）的Logical Expression和Physical Expression的集合，具体的示意图参见右图，整个矩形作为一个Group存在，里面分为3个部分，首先是关于Output的信息，然后紧接着是Logical Expression和Physical Expression，Logical Expression是对output应用Transformation Rule产生的表达式，Physical Expression是对LogicalExpression应用Implmentation Rule产生的Expression，下面具体介绍一下Transformation Rule和Implementation Rule的具体内容
![幻灯片17](https://user-images.githubusercontent.com/56379080/174482785-505d3ef2-6708-4457-bffd-e7b20a57373d.PNG)

下面介绍一下搜索过程，因为Volcano/Cascades优化器模型属于Push-Down大类，所以最开始的时候是从最顶层开始的，比如对于ABC三表JOIN问题，首先产生最顶层的Group，在这个Group里面应用Transformation Rule和Implmentation Rule，产生许多等价的逻辑表达式与物理表达式，然后再DFS搜索下去，不停地填Group里面的Logical Expression和Physical Expression，填写完成之后就可以利用记忆化搜索来搜寻最优的物理计划，在搜索过程中可以应用提前剪枝来减少搜索复杂度，提前剪枝做的就是当前有一个计划代价是100，在搜索过程中，有的计划代价还没搜索到最底面代价都已经来到了200，这个时候就不需要继续往下搜索了
这里还会有StartUp Cost优化、物理属性驱动优化等各种优化，这里就不详述了
![幻灯片18](https://user-images.githubusercontent.com/56379080/174482790-ad5230ad-d52a-4e18-8688-641bda1c699d.PNG)

在查询优化阶段还有几个很重要的问题需要解决，首先就是超多表JOIN问题，JOIN计划的数量是通过卡塔兰数来计算的，可以看到是根据JOIN表的数量增长而指数级增长，比如以n=3为例，一共有5种可能的join 顺序，更别说还要乘以表的物理实现数，搜索空间将是巨大的，很难完全搜索
![幻灯片19](https://user-images.githubusercontent.com/56379080/174482794-e85dfb4d-2c1a-46e0-b48b-327f98dd06c6.PNG)

在PG中超过8个表的JOIN就会走基因算法，首先是为了减少搜索空间就只考虑了左深树，然后会把它编码成字符串的形式，上面的连接树是用整数字符串'4-1-3-2'编码的，这就是说，首先连接关系'4'和'1'，然后'3'，然后是'2'，
然后会使用基因算法，来搜索较优的计划，基因算法属于启发式算法，主要包含两个步骤：进化和淘汰，进化操作使用的是交叉算法，具体的如图所示，两个染色体的某一相同位置处DNA被切断，前后两串分别交叉组合形成两个新的染色体，也称基因重组或杂交。
然后使用适应性函数来衡量每个基因的优劣（在JOIN问题中，适应性函数就是谁的代价更低），适应性比较高的，会被保存下来，作为种子参与下一轮的进化，就这样进行多次之后，就会寻找到较优的计划，但可能不是最优的。
![幻灯片20](https://user-images.githubusercontent.com/56379080/174482796-d1aaafab-cdcf-4ca7-92b4-ed25393b3c2d.PNG)

在分布式场景下，选择的是算子的分布式算法，而算子的分布式算法空间比算子本地算法的空间要大很多。
在分布式场景下，还增加了分区信息这个物理属性。分区信息主要包括如何分区以及分区的物理信息。分区信息决定了算子可以采用何种分布式算法。
在分布式场景下，分区裁剪/并行度优化/分区内(间)并行等因素也会增大分布式计划的优化复杂度。
现有的查询优化框架完全能够胜任，只不过计划空间非常的多，比如说对于并行度的优化OceanBase目前采用两阶段的方式来做分布式优化。在第一阶段，OceanBase基于所有表都是本地的假设生成一个最优本地计划。在第二阶段，OceanBase开始做并行优化, 用启发式规则来选择本地最优计划中算子的分布式算法。OceanBase二阶段的分布式计划优化方法能减少优化空间，降低优化复杂度，但是因为在第一阶段优化的时候没有考虑算子的分布式信息，所以可能导致生成的计划次优。
把并行信息综合到计划生成阶段就是一阶段的分布式查询计划优化，一阶段的分布式计划优化可能会导致计划空间增长很快，所以必须要有一些规则来减少计划空间或者跟本地优化一样在计划空间比较大的时候，使用遗传算法或者启发式规则来解决这个问题。
![幻灯片21](https://user-images.githubusercontent.com/56379080/174482804-79eddace-1650-4e0c-a6d8-97778709724e.PNG)

TP好比移动小土堆，不需要人很多，一个身强力壮的就行了（时延），AP好比是移动山，这个时候首先注重的应该是先堆人的数量（带宽），再考虑把人变得强壮（JIT、SIMD）
![幻灯片22](https://user-images.githubusercontent.com/56379080/174482810-2c5787e0-7b65-4ec0-9477-a7eba39d4298.PNG)

从两个角度划分，分别是控制流流向和每次交换的数据量大小
![幻灯片23](https://user-images.githubusercontent.com/56379080/174482815-7c9ae90c-de37-4e78-927d-f04b62efa7a1.PNG)

Volcano执行模型，最经典的执行模型，属于Pull，每次一行数据，调用顺序从上往下
![幻灯片24](https://user-images.githubusercontent.com/56379080/174482818-9d043e81-8b52-43ea-a438-fb91e5edafca.PNG)

Materialized执行模型，物化模型，数据从底往上返回，下层算子通知底层算子
![幻灯片25](https://user-images.githubusercontent.com/56379080/174482820-392442fc-2748-4c93-af6c-f14b17afbc79.PNG)

Vectorized执行模型，Volcano每次只拿一行数据，消耗在数据无关上的CPU过多，所以做了batch优化，还可以在算子内使用SIMD
![幻灯片26](https://user-images.githubusercontent.com/56379080/174482825-7387fff0-6994-4217-a220-1255a3468464.PNG)

Pipeline执行模型，流水线思想最早在福特汽车生产线上使用，CPU里面也采用了类似的思想，即：取指、译码、执行、访存、写回五个步骤做了流水线，这样可以把CPI送到1
![幻灯片27](https://user-images.githubusercontent.com/56379080/174482826-06ee082b-5ed2-423a-8d01-20c1d15dce6b.PNG)

下面是Pipeline执行模型在在CK里的实现
![幻灯片28](https://user-images.githubusercontent.com/56379080/174482828-79d7e3ee-ea1e-4e57-97a0-f0d550935d55.PNG)

JIT优化，是一种在运行时编译的技术，JIT 编译是两种传统的机器代码翻译方法的组合——提前编译 (AOT) 和解释——并结合了两者的一些优点和缺点。大致而言，JIT 编译结合了编译代码的速度和 解释的灵活性，解释器的开销以及编译和链接的额外开销（不仅仅是解释）。
![幻灯片29](https://user-images.githubusercontent.com/56379080/174482832-5488a1a9-a451-43b6-ae57-9ffa75909391.PNG)

在平时接触最多的是JVM立马的JIT技术，JVM中采用JIT技术来加速JAVA程序的执行，有这样的观察：80%的时间花在20%的程序上，所以JIT会有效，
而在数据库里面我们使用LLVM来做JIT，LLVM前后端分离架构，生成中间代码IR。
![幻灯片30](https://user-images.githubusercontent.com/56379080/174482834-4da7fde6-ca46-4910-bba2-49899f6cfb05.PNG)

JIT的原理分析，根本原理：冯诺依曼架构下，数据和指令不分
左边是一个函数的汇编代码，把汇编代码转为16进制就是右边copy_code函数里的数据，使用MMAP申请可执行内存，把代码拷贝进去，使用函数指针调用
![幻灯片31](https://user-images.githubusercontent.com/56379080/174482838-25b08aef-fef8-47f9-b0c5-79c4f155e82c.PNG)

在数据库中的应用之表达式编译，左边是表达式在内存中的结构，右边是执行的时候需要树形执行，表达式计算的时候在调虚表，查虚表，执行控制逻辑调用这些会消耗cpu cycle，
而经过JIT之后其实就是右图展示的代码拼接之后就可以减少这些cpu cycle的消耗了，在数据量很大的情况下就能显著提高性能
![幻灯片32](https://user-images.githubusercontent.com/56379080/174482841-d0d74daf-f662-421f-a105-a470742752e5.PNG)

上文讲的是表达式编译，下面讲一下整个计划的编译，每个算子都实现了produce方法和consume方法，produce方法负责调用下层算子的produce方法，consume方法要返回每个算子的实现，然后把它们拼接成代码段，送进编译器，编译之后执行就可以了
![幻灯片33](https://user-images.githubusercontent.com/56379080/174482843-fd2d321b-bcab-46cd-a5cc-3f50ffc27b73.PNG)

还有一项优化技术即SIMD技术被广泛应用，CPU的大量晶体管花在了cache和控制器（好像是85%），真正计算的部分很少，所以可以把计算单元做的宽一点来加速计算
列存中很有用；需要对齐；SSE2和AVX不能混用
MIMD是多线程编程，SISD是常用的编程模式
![幻灯片34](https://user-images.githubusercontent.com/56379080/174482844-cfe7cb13-77c3-42b6-ab99-04fcb57dc1e2.PNG)

怎么实现SIMD
![幻灯片35](https://user-images.githubusercontent.com/56379080/174482846-b088ae88-4d5b-4951-9dfa-9623296a0e59.PNG)

SIMD应用实例
![幻灯片36](https://user-images.githubusercontent.com/56379080/174482850-e0b7cd08-67b4-4058-979e-bcd41d817ec5.PNG)

查询组推荐
![幻灯片37](https://user-images.githubusercontent.com/56379080/174482856-4b6d7626-dd59-4c36-bb78-93957f95afef.PNG)


![幻灯片38](https://user-images.githubusercontent.com/56379080/174482859-584ca0da-71f6-40a5-92e2-c534f5f95505.PNG)





